{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672c9dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import tgt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from re import match, sub, findall, finditer\n",
    "\n",
    "\n",
    "root_dir = '../'\n",
    "word_level_timing = root_dir+'word_level_timings'\n",
    "motion_label = root_dir+'motion_labels' \n",
    "original_annotation = root_dir + 'transcriptions_annotations'\n",
    "# word_level     = root_dir + 'word_level'\n",
    "# video          = root_dir + 'video' \n",
    "# audio          = root_dir +'audio' \n",
    "# documents      = root_dir + 'documents', \n",
    "# metadata       = root_dir+ 'metadata', \n",
    "# transcriptions = root_dir+'transcriptions_annotations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9a3619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../transcriptions_annotations/r19/r19.TextGrid', '../transcriptions_annotations/r18/r18.TextGrid', '../transcriptions_annotations/r13/r13.TextGrid', '../transcriptions_annotations/r9/r9.TextGrid', '../transcriptions_annotations/r10/r10.TextGrid', '../transcriptions_annotations/r1/r1.TextGrid', '../transcriptions_annotations/r4/r4.TextGrid', '../transcriptions_annotations/r15/r15.TextGrid', '../transcriptions_annotations/r7/r7.TextGrid', '../transcriptions_annotations/r5/r5.TextGrid', '../transcriptions_annotations/r17/r17.TextGrid', '../transcriptions_annotations/r12/r12.TextGrid', '../transcriptions_annotations/r2/r2.TextGrid', '../transcriptions_annotations/r3/r3.TextGrid', '../transcriptions_annotations/r6/r6.TextGrid', '../transcriptions_annotations/r14/r14.TextGrid', '../transcriptions_annotations/r16/r16.TextGrid', '../transcriptions_annotations/r11/r11.TextGrid', '../transcriptions_annotations/r8/r8.TextGrid']\n"
     ]
    }
   ],
   "source": [
    "def get_all_textgrid_files(path):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".TextGrid\"):\n",
    "                filenames.append(os.path.join(root, file))\n",
    "    return filenames\n",
    "annotations = get_all_textgrid_files(original_annotation)\n",
    "print(annotations)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84ca7a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_utt(utt, literal=False):\n",
    "    if not literal:\n",
    "        #replace variants, partial and misspoken words with standard spelling\n",
    "        utt = sub(\"\"\"<[vpm]=\"(.+?)\">.+?</[vpm]>\"\"\", lambda m:m.group(1), utt)\n",
    "        #remove fillers like \"{F aehm}\" entirely\n",
    "        utt = sub(\"\"\"{.*?}\"\"\", \"\", utt)\n",
    "        \n",
    "        #TO DO: resolve complex replacements like \"(der + der) + die) Katze\"\n",
    "        \n",
    "    else:\n",
    "        #remove brackets from fillers, i.e. \"{F aehm}\" becomes \"aehm\"\n",
    "        utt = sub(\"\"\"{(.*?)}\"\"\",lambda m:m.group(1),utt)\n",
    "    #remove all remaining xml-style tags    \n",
    "    utt = sub(\"\"\"<.*?>\"\"\",\"\",utt)\n",
    "    #remove open tags at the end of an utterance (can be removed once problems with the TextGrids are fixed)\n",
    "    utt = sub(\"\"\"<.*$\"\"\",\"\",utt)\n",
    "    #remove all remaining punctuation and brackets\n",
    "    utt = sub(\"\"\"[\\.:;,\\(\\)\\+\\$]\"\"\",\"\",utt)\n",
    "    #remove whitespace at the beginning and end of an utterance\n",
    "    utt = utt.strip()\n",
    "    #replace any amount of whitespace with a single space\n",
    "    utt = sub(\"\"\"\\s+\"\"\",\" \",utt)\n",
    "    return utt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e35ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'O', 'A-utts', 'B-laughter']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'B-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'B-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'O', 'A-utts', 'B-laughter']\n",
      "['B-utts', 'B-turns', 'A-turns', 'O', 'A-laughter', 'Part', 'Comments', 'A-utts', 'B-laughter']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'O', 'A-utts', 'Part', 'B-laughter', 'A-laughter']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'O', 'A-utts', 'B-laughter']\n",
      "['B-utts', 'B-turns', 'A-turns', 'A-laughter', 'Part', 'B-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-turns', 'A-turns', 'Comments', 'B-utts', 'Part', 'B-laughter', 'A-laughter', 'A-utts']\n",
      "['B-utts', 'B-turns', 'A-turns', 'Comments', 'A-laughter', 'Part', 'B-laughter', 'A-utts']\n"
     ]
    }
   ],
   "source": [
    "for index, f in enumerate(annotations):\n",
    "    clear_text = list()\n",
    "    textgrid = tgt.read_textgrid(f)\n",
    "    tier_names = textgrid.get_tier_names()\n",
    "    print(tier_names)\n",
    "    for names in tier_names:\n",
    "        text_tier = textgrid.get_tier_by_name(names)\n",
    "        for annotation in text_tier.annotations:\n",
    "            annotation.text = clean_utt(annotation.text)\n",
    "    tgt.io.write_to_file(textgrid, './clean_text/'+str(f.split('/')[3].split('.')[0])+\".textgrid\")\n",
    "    # dataframe = pd.DataFrame(clear_text, columns=['file_name', 'tier_name', 'text', 'clean_text', 'start_time', 'end_time'])\n",
    "    # # print(f.split('/')[3].split('.')[0])\n",
    "    # dataframe.to_csv('./clean_text/'+str(f.split('/')[3].split('.')[0])+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b4b242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
