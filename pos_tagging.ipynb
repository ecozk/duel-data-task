{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__delitem__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getitem__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__len__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_get_annotation_index_by_end_time', '_get_annotation_index_by_start_time', '_get_annotation_index_range_between_timepoints', '_get_annotation_indices_by_time', '_get_annotations', '_get_end_time', '_get_start_time', '_set_end_time', '_set_start_time', 'add_annotation', 'add_annotations', 'annotations', 'delete_annotation_by_end_time', 'delete_annotation_by_start_time', 'delete_annotations_between_timepoints', 'delete_annotations_by_time', 'delete_annotations_with_text', 'delete_empty_annotations', 'end_time', 'get_annotation_by_end_time', 'get_annotation_by_start_time', 'get_annotations_between_timepoints', 'get_annotations_by_time', 'get_annotations_with_matching_text', 'get_annotations_with_text', 'get_nearest_annotation', 'start_time', 'tier_type']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import tgt\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import torch\n",
    "print(dir(tgt.Tier))\n",
    "root_dir = './'\n",
    "word_level_timing = root_dir+'word_level_timing'\n",
    "motion_label = root_dir+'motion_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Sonne scheint am Himmel und die Vögel singen.\n"
     ]
    }
   ],
   "source": [
    "german_text = \"Die Sonne scheint am Himmel und die Vögel singen.\"\n",
    "german_tagger = spacy.load(\"de_core_news_sm\")\n",
    "doc = german_tagger(german_text)\n",
    "print(doc)\n",
    "# Extract tokens and POS tags\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./word_level_timing/r1A_wordlevel.TextGrid', './word_level_timing/r13A_wordlevel.TextGrid', './word_level_timing/r3A_wordlevel.TextGrid', './word_level_timing/r19B_wordlevel.TextGrid', './word_level_timing/r15B_wordlevel.TextGrid', './word_level_timing/r11B_wordlevel.TextGrid', './word_level_timing/r19A_wordlevel.TextGrid', './word_level_timing/r2B_wordlevel.TextGrid', './word_level_timing/r3B_wordlevel.TextGrid', './word_level_timing/r12B_wordlevel.TextGrid', './word_level_timing/r9A_wordlevel.TextGrid', './word_level_timing/r10A_wordlevel.TextGrid', './word_level_timing/r9B_wordlevel.TextGrid', './word_level_timing/r18A_wordlevel.TextGrid', './word_level_timing/r17B_wordlevel.TextGrid', './word_level_timing/r8B_wordlevel.TextGrid', './word_level_timing/r15A_wordlevel.TextGrid', './word_level_timing/r5A_wordlevel.TextGrid', './word_level_timing/r12A_wordlevel.TextGrid', './word_level_timing/r7B_wodlevel.TextGrid', './word_level_timing/r6B_wordleve.TextGrid', './word_level_timing/r5B_wordlevel.TextGrid', './word_level_timing/r17A_wordlevel.TextGrid', './word_level_timing/r8A_wordlevel.TextGrid', './word_level_timing/r18B_wordlevel.TextGrid', './word_level_timing/r2A_wordlevel.TextGrid', './word_level_timing/r16B_wordlevel.TextGrid', './word_level_timing/r10B_wordlevel.TextGrid', './word_level_timing/r1B_wordlevel.TextGrid', './word_level_timing/r11A_wordlevel.TextGrid', './word_level_timing/r4A_wordlevel.TextGrid', './word_level_timing/r6A_wordlevel.TextGrid', './word_level_timing/r14B_wordlevel.TextGrid', './word_level_timing/r16A_wordlevel.TextGrid', './word_level_timing/r4B_wordlevel.TextGrid', './word_level_timing/r7A_wordlevel.TextGrid', './word_level_timing/r13B_wordlevel.TextGrid', './word_level_timing/r14A_wordlevel.TextGrid']\n"
     ]
    }
   ],
   "source": [
    "def get_all_textgrid_files(path):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".TextGrid\"):\n",
    "                filenames.append(os.path.join(root, file))\n",
    "    return filenames\n",
    "word_level_timing_annotation = get_all_textgrid_files(word_level_timing)\n",
    "print(word_level_timing_annotation)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing file ./word_level_timing/r10B_wordlevel.TextGrid\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not add object Interval(469.468776, 469.920272, \"n\") to this tier: Overlap.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb Cell 4\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./word_level_timing/r10B_wordlevel.TextGrid\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprocessing file \u001b[39m\u001b[39m{\u001b[39;00mf\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     textgrid\u001b[39m=\u001b[39m tgt\u001b[39m.\u001b[39;49mread_textgrid(f)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     tier_names \u001b[39m=\u001b[39m textgrid\u001b[39m.\u001b[39mget_tier_names()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mfor\u001b[39;00m names \u001b[39min\u001b[39;00m tier_names:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt/lib/python3.11/site-packages/tgt/io3.py:51\u001b[0m, in \u001b[0;36mread_textgrid\u001b[0;34m(filename, encoding, include_empty_intervals)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m# Determine the TextGrid format.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m stg[\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39mstartswith(\u001b[39m'\u001b[39m\u001b[39mxmin\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m read_long_textgrid(filename, stg, include_empty_intervals)\n\u001b[1;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     \u001b[39mreturn\u001b[39;00m read_short_textgrid(filename, stg, include_empty_intervals)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt/lib/python3.11/site-packages/tgt/io3.py:160\u001b[0m, in \u001b[0;36mread_long_textgrid\u001b[0;34m(filename, stg, include_empty_intervals)\u001b[0m\n\u001b[1;32m    158\u001b[0m num_obj \u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(get_attr_val(stg[index \u001b[39m+\u001b[39m \u001b[39m5\u001b[39m]))\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m get_attr_val(stg[index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIntervalTier\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     tg\u001b[39m.\u001b[39madd_tier(read_interval_tier(stg[index:index \u001b[39m+\u001b[39;49m \u001b[39m6\u001b[39;49m \u001b[39m+\u001b[39;49m num_obj \u001b[39m*\u001b[39;49m \u001b[39m4\u001b[39;49m]))\n\u001b[1;32m    161\u001b[0m     index \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m6\u001b[39m \u001b[39m+\u001b[39m (num_obj \u001b[39m*\u001b[39m \u001b[39m4\u001b[39m)\n\u001b[1;32m    162\u001b[0m \u001b[39melif\u001b[39;00m get_attr_val(stg[index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]) \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTextTier\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt/lib/python3.11/site-packages/tgt/io3.py:130\u001b[0m, in \u001b[0;36mread_long_textgrid.<locals>.read_interval_tier\u001b[0;34m(stg_extract)\u001b[0m\n\u001b[1;32m    128\u001b[0m     text \u001b[39m=\u001b[39m get_attr_val(stg_extract[i \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m])[\u001b[39m1\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m# text w/o quotes\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     \u001b[39mif\u001b[39;00m text\u001b[39m.\u001b[39mstrip() \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m include_empty_intervals_this_tier:\n\u001b[0;32m--> 130\u001b[0m         it\u001b[39m.\u001b[39;49madd_annotation(Interval(\n\u001b[1;32m    131\u001b[0m             Time(get_attr_val(stg_extract[i])), \u001b[39m# left bound\u001b[39;49;00m\n\u001b[1;32m    132\u001b[0m             Time(get_attr_val(stg_extract[i \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m])), \u001b[39m# right bound\u001b[39;49;00m\n\u001b[1;32m    133\u001b[0m             deescape_text(text)))\n\u001b[1;32m    134\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m it\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt/lib/python3.11/site-packages/tgt/core.py:205\u001b[0m, in \u001b[0;36mTier.add_annotation\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_objects\u001b[39m.\u001b[39minsert(position, obj)\n\u001b[1;32m    204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mCould not add object \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m to this tier: Overlap.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[39mrepr\u001b[39m(obj)))\n",
      "\u001b[0;31mValueError\u001b[0m: Could not add object Interval(469.468776, 469.920272, \"n\") to this tier: Overlap."
     ]
    }
   ],
   "source": [
    "pos_tag = []\n",
    "for index, f in enumerate(word_level_timing_annotation):\n",
    "    if f == './word_level_timing/r10B_wordlevel.TextGrid':\n",
    "        print(f'processing file {f}')\n",
    "        textgrid= tgt.read_textgrid(f)\n",
    "        tier_names = textgrid.get_tier_names()\n",
    "        for names in tier_names:\n",
    "            text_tier = textgrid.get_tier_by_name(names)\n",
    "            for annotation in text_tier.annotations:\n",
    "                doc = german_tagger(annotation.text)\n",
    "                for token in doc:\n",
    "                    pos_tag.append((token.text, token.pos_, str(f.split('/')[2]).split('.')[0].split('_')[0], names, annotation.start_time, annotation.end_time))\n",
    "        dataframe = pd.DataFrame(pos_tag, columns=['text', 'pos_tag', 'session', 'tier_name', 'start_time', 'end_time'])\n",
    "        dataframe.to_csv('./pos_tagging/'+str(f.split('/')[2].split('.')[0])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to define a dataset class first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLevelTiming(torch.utils.data.Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, emdbedding_diminput_shape):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # self.word_embedding = \n",
    "        # self.lstm1 = nn.LSTM(embedding_dim, hidden_dim)\n",
    "    def forward(self, x)\n",
    "        # embeds = self.word_embedding\n",
    "        # lstm_out, _ = self.lstm(embeds.view(len(x), 1, -1))\n",
    "        # tag_space = self.hidden2tag(lstm_out.view(len(x), -1))\n",
    "        # tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        # return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "def train(train_loader,val_loader, model, loss_function, optimizer, epochs, device):\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "\n",
    "    history = {}\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "    start_time_sec = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model=model.to(device)\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        num_train_correct = 0\n",
    "        num_train_examples = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            target = batch['label'].to(device)\n",
    "\n",
    "            output = model(images.float())\n",
    "            loss = loss_function(output, target.float())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.data.item()*images.size(0)\n",
    "            num_train_correct  += (torch.max(output, 1)[1] == target).sum().item()\n",
    "            num_train_examples += images.shape[0]\n",
    "        train_acc =  num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "\n",
    "        model.eval()\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            target = batch['label'].to(device)\n",
    "\n",
    "            output = model(images.float())\n",
    "            loss = loss_function(output, target.float())\n",
    "\n",
    "            val_loss         += loss.data.item()*images.size(0)\n",
    "            num_val_correct  += (torch.max(output, 1)[1] == target).sum().item()\n",
    "            num_val_examples += images.shape[0]\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "              (epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "         # END OF TRAINING LOOP\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
