{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import tgt\n",
    "import os\n",
    "import random\n",
    "import spacy\n",
    "import torch\n",
    "root_dir = './'\n",
    "word_level_timing = root_dir+'word_level_timing'\n",
    "motion_label = root_dir+'motion_labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Die Sonne scheint am Himmel und die Vögel singen.\n"
     ]
    }
   ],
   "source": [
    "german_text = \"Die Sonne scheint am Himmel und die Vögel singen.\"\n",
    "german_tagger = spacy.load(\"de_core_news_sm\")\n",
    "doc = german_tagger(german_text)\n",
    "print(doc)\n",
    "# Extract tokens and POS tags\n",
    "# for token in doc:\n",
    "#     print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./word_level_timing/r1A_wordlevel.TextGrid', './word_level_timing/r13A_wordlevel.TextGrid', './word_level_timing/r3A_wordlevel.TextGrid', './word_level_timing/r19B_wordlevel.TextGrid', './word_level_timing/r15B_wordlevel.TextGrid', './word_level_timing/r11B_wordlevel.TextGrid', './word_level_timing/r19A_wordlevel.TextGrid', './word_level_timing/r2B_wordlevel.TextGrid', './word_level_timing/r3B_wordlevel.TextGrid', './word_level_timing/r12B_wordlevel.TextGrid', './word_level_timing/r9A_wordlevel.TextGrid', './word_level_timing/r10A_wordlevel.TextGrid', './word_level_timing/r9B_wordlevel.TextGrid', './word_level_timing/r18A_wordlevel.TextGrid', './word_level_timing/r17B_wordlevel.TextGrid', './word_level_timing/r8B_wordlevel.TextGrid', './word_level_timing/r15A_wordlevel.TextGrid', './word_level_timing/r5A_wordlevel.TextGrid', './word_level_timing/r12A_wordlevel.TextGrid', './word_level_timing/r7B_wodlevel.TextGrid', './word_level_timing/r6B_wordleve.TextGrid', './word_level_timing/r5B_wordlevel.TextGrid', './word_level_timing/r17A_wordlevel.TextGrid', './word_level_timing/r8A_wordlevel.TextGrid', './word_level_timing/r18B_wordlevel.TextGrid', './word_level_timing/r2A_wordlevel.TextGrid', './word_level_timing/r16B_wordlevel.TextGrid', './word_level_timing/r10B_wordlevel.TextGrid', './word_level_timing/r1B_wordlevel.TextGrid', './word_level_timing/r11A_wordlevel.TextGrid', './word_level_timing/r4A_wordlevel.TextGrid', './word_level_timing/r6A_wordlevel.TextGrid', './word_level_timing/r14B_wordlevel.TextGrid', './word_level_timing/r16A_wordlevel.TextGrid', './word_level_timing/r4B_wordlevel.TextGrid', './word_level_timing/r7A_wordlevel.TextGrid', './word_level_timing/r13B_wordlevel.TextGrid', './word_level_timing/r14A_wordlevel.TextGrid']\n"
     ]
    }
   ],
   "source": [
    "def get_all_textgrid_files(path):\n",
    "    filenames = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".TextGrid\"):\n",
    "                filenames.append(os.path.join(root, file))\n",
    "    return filenames\n",
    "word_level_timing_annotation = get_all_textgrid_files(word_level_timing)\n",
    "print(word_level_timing_annotation)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./word_level_timing/r1A_wordlevel.TextGrid\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tier.add_annotations() got an unexpected keyword argument 'object'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         doc \u001b[39m=\u001b[39m german_tagger(annotation\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m doc:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m             text_tier\u001b[39m.\u001b[39;49madd_annotations(\u001b[39mobject\u001b[39;49m\u001b[39m=\u001b[39;49mtoken\u001b[39m.\u001b[39;49mpos_)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m tgt\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mwrite_to_file(textgrid, \u001b[39m'\u001b[39m\u001b[39m./pos_tagging/\u001b[39m\u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(f\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m/\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m2\u001b[39m])\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m0\u001b[39m]\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.TextGrid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# dataframe = pd.DataFrame(clear_text, columns=['file_name', 'tier_name', 'text', 'clean_text', 'start_time', 'end_time'])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# # print(f.split('/')[3].split('.')[0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/pos_tagging.ipynb#W3sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m# dataframe.to_csv('./clean_text/'+str(f.split('/')[3].split('.')[0])+'.csv')\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tier.add_annotations() got an unexpected keyword argument 'object'"
     ]
    }
   ],
   "source": [
    "for index, f in enumerate(word_level_timing_annotation):\n",
    "    textgrid= tgt.read_textgrid(f)\n",
    "    print(f)\n",
    "    tier_names = textgrid.get_tier_names()\n",
    "#     print(tier_names)\n",
    "    for names in tier_names:\n",
    "        text_tier = textgrid.get_tier_by_name(names)\n",
    "        for annotation in text_tier.annotations:\n",
    "            doc = german_tagger(annotation.text)\n",
    "            for token in doc:\n",
    "                text_tier.add_annotations(token.pos_)\n",
    "    tgt.io.write_to_file(textgrid, './pos_tagging/'+str(f.split('/')[2]).split('.')[0]+\".TextGrid\")\n",
    "    # dataframe = pd.DataFrame(clear_text, columns=['file_name', 'tier_name', 'text', 'clean_text', 'start_time', 'end_time'])\n",
    "    # # print(f.split('/')[3].split('.')[0])\n",
    "    # dataframe.to_csv('./clean_text/'+str(f.split('/')[3].split('.')[0])+'.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to define a dataset class first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordLevelTiming(torch.utils.data.Dataset):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "class RNNModel(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim, emdbedding_diminput_shape):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        # self.word_embedding = \n",
    "        # self.lstm1 = nn.LSTM(embedding_dim, hidden_dim)\n",
    "    def forward(self, x)\n",
    "        # embeds = self.word_embedding\n",
    "        # lstm_out, _ = self.lstm(embeds.view(len(x), 1, -1))\n",
    "        # tag_space = self.hidden2tag(lstm_out.view(len(x), -1))\n",
    "        # tag_scores = F.log_softmax(tag_space, dim=1)\n",
    "        # return tag_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "def train(train_loader,val_loader, model, loss_function, optimizer, epochs, device):\n",
    "    print('train() called: model=%s, opt=%s(lr=%f), epochs=%d, device=%s\\n' % \\\n",
    "          (type(model).__name__, type(optimizer).__name__,\n",
    "           optimizer.param_groups[0]['lr'], epochs, device))\n",
    "\n",
    "    history = {}\n",
    "    history['loss'] = []\n",
    "    history['val_loss'] = []\n",
    "    history['acc'] = []\n",
    "    history['val_acc'] = []\n",
    "    start_time_sec = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        model=model.to(device)\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        num_train_correct = 0\n",
    "        num_train_examples = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            images = batch['image'].to(device)\n",
    "            target = batch['label'].to(device)\n",
    "\n",
    "            output = model(images.float())\n",
    "            loss = loss_function(output, target.float())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.data.item()*images.size(0)\n",
    "            num_train_correct  += (torch.max(output, 1)[1] == target).sum().item()\n",
    "            num_train_examples += images.shape[0]\n",
    "        train_acc =  num_train_correct / num_train_examples\n",
    "        train_loss  = train_loss / len(train_loader.dataset)\n",
    "\n",
    "        # --- EVALUATE ON VALIDATION SET -------------------------------------\n",
    "\n",
    "        model.eval()\n",
    "        val_loss       = 0.0\n",
    "        num_val_correct  = 0\n",
    "        num_val_examples = 0\n",
    "\n",
    "        for batch in val_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            target = batch['label'].to(device)\n",
    "\n",
    "            output = model(images.float())\n",
    "            loss = loss_function(output, target.float())\n",
    "\n",
    "            val_loss         += loss.data.item()*images.size(0)\n",
    "            num_val_correct  += (torch.max(output, 1)[1] == target).sum().item()\n",
    "            num_val_examples += images.shape[0]\n",
    "        val_acc  = num_val_correct / num_val_examples\n",
    "        val_loss = val_loss / len(val_loader.dataset)\n",
    "        print('Epoch %3d/%3d, train loss: %5.2f, train acc: %5.2f, val loss: %5.2f, val acc: %5.2f' % \\\n",
    "              (epoch+1, epochs, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "        history['loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['acc'].append(train_acc)\n",
    "        history['val_acc'].append(val_acc)\n",
    "\n",
    "         # END OF TRAINING LOOP\n",
    "    end_time_sec       = time.time()\n",
    "    total_time_sec     = end_time_sec - start_time_sec\n",
    "    time_per_epoch_sec = total_time_sec / epochs\n",
    "    print()\n",
    "    print('Time total:     %5.2f sec' % (total_time_sec))\n",
    "    print('Time per epoch: %5.2f sec' % (time_per_epoch_sec))\n",
    "\n",
    "    return history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
