{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efa89570-4ab6-42a6-9062-242351edc9f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import Counter, defaultdict\n",
    "import tgt\n",
    "from copy import deepcopy\n",
    "from re import match, sub, findall, finditer\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bca83b1a-21f7-4843-9901-4dd6cc3edcc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root_dir = '../'\n",
    "word_level_timing = root_dir + 'word_level_timings'\n",
    "motion_label = root_dir + 'motion_labels' \n",
    "original_annotation = root_dir + 'transcriptions_annotations'\n",
    "lang = 'de'\n",
    "target_dir = \"./DUEL/{}\".format(lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba767561-91e2-477a-b175-f7a8f44259fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "task_index = {\n",
    "    1 : \"dream_apartment\",\n",
    "    2: \"film_script\",\n",
    "    3: \"border_control\"\n",
    "             }\n",
    "\n",
    "legal_tiers = {\"A-utts\" : [u\"A\", u\"A-utts;\"], \n",
    "               \"B-utts\" : [u\"B\", u\"B-utts;\", u\"B_utts\"], \n",
    "               \"A-turns\" : [u\"A-turns;\",\"A_turns\"], \n",
    "               \"B-turns\" : [ u\"B-turns;\",u\"B_turns\", u\"B-turns    \"],\n",
    "               \"A-laughter\" : [], \n",
    "               \"B-laughter\" : [u\"Bâˆ’laughter\"],\n",
    "               \"A-en\" : [u\"A-eng\", u\"A-english\",\n",
    "                         u\"A-fr_en\", u\"A-fr-en\",\n",
    "                         u\"A-fr_en;\",u\"Translation A\",\n",
    "                         u\"translation A\", u\"A translation\", u\"A Translation\"], \n",
    "               \"B-en\" : [u\"B-eng\", u\"B-english\",\n",
    "                         u\"B-fr_en\", u\"B-fr_en;\",\n",
    "                         u\"B_fr-en\", u\"Translation B\", \n",
    "                         u\"translation B\", u\"B translation\",\n",
    "                         u\"B Translation\", u\"B-fr-en\"],\n",
    "               \"Comments\" : [u\"Comments & questions\",\n",
    "                             u\"comments\", u\"Problems\"], \n",
    "               \"Part\" : [u\"part\"], \n",
    "               \"O\" : [u\"E\"]\n",
    "              }\n",
    "\n",
    "c = Counter()\n",
    "missing_c = defaultdict(list)\n",
    "global_tag_count = Counter()\n",
    "log_file = open(\"{}_errors.log\".format(lang), \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b3a93ec-dc3e-4312-9abf-a155d2226595",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRead textgrid function\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read textgrid function\n",
    "\"\"\"\n",
    "# simply : tg = tgt.read_textgrid(tg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9220aa7-a09e-4660-883a-67b36eeceb70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_utt(utt, literal=False):\n",
    "    if not literal:\n",
    "        #replace variants, partial and misspoken words with standard spelling\n",
    "        utt = sub(\"\"\"<[vpm]=\"(.+?)\">.+?</[vpm]>\"\"\", lambda m:m.group(1), utt)\n",
    "        #remove fillers like \"{F aehm}\" entirely\n",
    "        utt = sub(\"\"\"{.*?}\"\"\", \"\", utt)\n",
    "        \n",
    "        #TO DO: resolve complex replacements like \"(der + der) + die) Katze\"\n",
    "        \n",
    "    else:\n",
    "        #remove brackets from fillers, i.e. \"{F aehm}\" becomes \"aehm\"\n",
    "        utt = sub(\"\"\"{(.*?)}\"\"\",lambda m:m.group(1),utt)\n",
    "    #remove all remaining xml-style tags    \n",
    "    utt = sub(\"\"\"<.*?>\"\"\",\"\",utt)\n",
    "    #remove open tags at the end of an utterance (can be removed once problems with the TextGrids are fixed)\n",
    "    utt = sub(\"\"\"<.*$\"\"\",\"\",utt)\n",
    "    #remove all remaining punctuation and brackets\n",
    "    utt = sub(\"\"\"[\\.:;,\\(\\)\\+\\$]\"\"\",\"\",utt)\n",
    "    #remove whitespace at the beginning and end of an utterance\n",
    "    utt = utt.strip()\n",
    "    #replace any amount of whitespace with a single space\n",
    "    utt = sub(\"\"\"\\s+\"\"\",\" \",utt)\n",
    "    return utt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1532cc9c-06a6-4fd7-9370-ae0bde01672f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Methods to consume textgrids and convert to the disfluency\n",
    "corpus style for consistency across different possible raw formats.\n",
    "\n",
    "This file is distributed as part of DUEL corpus.\n",
    "\"\"\"\n",
    "\n",
    "# corpus, start_time deleted as parameters\n",
    "# how to do the basic version? e rps and f\n",
    "def disfluency_tags(utt):\n",
    "    \"\"\"returns the list of tags for each word (simply defined by split)\n",
    "    and also the list of tags for boundaries (one more than the utt length) \n",
    "    for repair points and laughter bouts. NB problem is: the laughter bout itself is a word\n",
    "    may in fact instead need to do this after we establish which words are proper words\"\"\"\n",
    "    utt = utt.split()\n",
    "    labels = [\"\",] * len(utt)\n",
    "    boundaries = [\"\",] * (len(utt)+1) # where do we use this?\n",
    "    inReparandum = 0\n",
    "    inRepair = 0\n",
    "    inFP = False # why does this start with True, changed to False\n",
    "    inLS = False\n",
    "    for i in range(0,len(utt)):\n",
    "        word = utt[i]\n",
    "        word_clean = clean_utt(word) # this is added\n",
    "        if word_clean == \"-\": # this was \"-\"\n",
    "            continue\n",
    "        \n",
    "        if \"<laughter>\" in word or \"<laughter/>\" in word:\n",
    "            inLS = True\n",
    "        if \"<p\" in word:\n",
    "            labels[i] = \"<p/>\"\n",
    "        for j in range(0,len(word)):\n",
    "            filled_pause_begin = False\n",
    "            c = word[j]\n",
    "            if c==\"(\":\n",
    "                inReparandum+=1\n",
    "            if c == \"{\":\n",
    "                if j == len(word)-1:\n",
    "                    pass #edit term (non-fp)\n",
    "                elif word[j+1] == \"F\":\n",
    "                    inFP = True\n",
    "                    filled_pause_begin = True\n",
    "                else:\n",
    "                    pass\n",
    "                    \n",
    "        if inFP or filled_pause_begin: # using and instead of or removed all edit tags in {F Ahm\n",
    "            labels[i] = \"<e/>\"\n",
    "        elif inReparandum>0 and inFP==False:\n",
    "            labels[i] = \"<rm/>\"\n",
    "        elif inRepair>0 and inFP==False:\n",
    "            labels[i] = \"<rp/>\" # = instead of += for only one tag. however, open and close </rm> </rm> should be +=\n",
    "            \n",
    "        if inLS==True:\n",
    "            labels[i] = \"<ls/>\"\n",
    "        elif \"</laughter>\" in word:\n",
    "            inLS=False\n",
    "            \n",
    "        for j in range(0,len(word)):\n",
    "            c = word[j]\n",
    "            if c == \")\": inRepair-=1 # for now counting interegnum within the repairs\n",
    "            if c == \"+\": \n",
    "                inRepair += 1\n",
    "                inReparandum -= 1\n",
    "            if c ==\"}\": #out of the filled pause\n",
    "                inFP=False\n",
    "                \n",
    "        # fluent terms\n",
    "        if labels[i] == \"\":\n",
    "            labels[i] = \"<f/>\"               \n",
    "    #if inLS == True:\n",
    "    #    print \"WARNING NO LS END\", corpus, start_time\n",
    "        #raw_input()\n",
    "        \n",
    "        # labels[i-1] + utt[i] + labels[i]\n",
    "       # sandwiched_labels = labels[0] + utt + labels[1]\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "274dc23b-0d37-40d0-ab8c-ffa591086efd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def textgrid_to_dict(tgfile):\n",
    "    \"\"\"Returns a dict with the tier names as keys and a list of\n",
    "    intervals of (start_time, end_time, text) as values.\n",
    "\n",
    "    :param tgfile: path to textgrid file\"\"\"\n",
    "\n",
    "    textgrid = tgt.read_textgrid(textgrid_file_name)\n",
    "    \n",
    "    tgdict = dict()\n",
    "    for tiername in textgrid.get_tier_names():\n",
    "        tgdict[tiername] = []\n",
    "        for textinterval in textgrid.get_tier_by_name(tiername):\n",
    "            if textinterval.text != '<sil>':\n",
    "                tgdict[tiername].append((float(textinterval.start_time),\n",
    "                                         float(textinterval.end_time),\n",
    "                                         str(textinterval.text\n",
    "                                             .encode(\"utf-8\").decode(\"utf-8\"))))\n",
    "    return tgdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aacef611-5c06-4bc0-b874-a97e97e91c22",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../transcriptions_annotations/.ipynb_checkpoints/.ipynb_checkpoints.TextGrid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m textgrid_file_name_target \u001b[39m=\u001b[39m target_dir \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m experiment_name \u001b[39m+\u001b[39m os\u001b[39m.\u001b[39msep \u001b[39m+\u001b[39m experiment_name \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.TextGrid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# read textgrids\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m textgrid_dict \u001b[39m=\u001b[39m textgrid_to_dict(textgrid_file_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m utts \u001b[39min\u001b[39;00m textgrid_dict[\u001b[39m'\u001b[39m\u001b[39mA-utts\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mprint\u001b[39m(utts[\u001b[39m2\u001b[39m])\n",
      "\u001b[1;32m/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb Cell 8\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtextgrid_to_dict\u001b[39m(tgfile):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Returns a dict with the tier names as keys and a list of\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m    intervals of (start_time, end_time, text) as values.\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m    :param tgfile: path to textgrid file\"\"\"\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     textgrid \u001b[39m=\u001b[39m tgt\u001b[39m.\u001b[39;49mread_textgrid(textgrid_file_name)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     tgdict \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/phantom/repair/de/duel-data-task/disf_tagging.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mfor\u001b[39;00m tiername \u001b[39min\u001b[39;00m textgrid\u001b[39m.\u001b[39mget_tier_names():\n",
      "File \u001b[0;32m~/miniconda3/envs/pyt/lib/python3.11/site-packages/tgt/io3.py:41\u001b[0m, in \u001b[0;36mread_textgrid\u001b[0;34m(filename, encoding, include_empty_intervals)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_textgrid\u001b[39m(filename, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m, include_empty_intervals\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Read a Praat TextGrid file and return a TextGrid object. \u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[39m    If include_empty_intervals is False (the default), empty intervals\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39m    are excluded. If True, they are included. Empty intervals from specific\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m    tiers can be also included by specifying tier names as a string (for one tier)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m    or as a list.'''\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrt\u001b[39;49m\u001b[39m'\u001b[39;49m, encoding\u001b[39m=\u001b[39;49mencoding) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     42\u001b[0m         \u001b[39m# Read whole file into memory ignoring empty lines and lines consisting\u001b[39;00m\n\u001b[1;32m     43\u001b[0m         \u001b[39m# solely of a single double quotes.\u001b[39;00m\n\u001b[1;32m     44\u001b[0m         stg \u001b[39m=\u001b[39m [line\u001b[39m.\u001b[39mstrip() \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m f\u001b[39m.\u001b[39mreadlines()\n\u001b[1;32m     45\u001b[0m             \u001b[39mif\u001b[39;00m line\u001b[39m.\u001b[39mstrip() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m]]\n\u001b[1;32m     46\u001b[0m     \u001b[39mif\u001b[39;00m ((stg[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFile type = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mooTextFile\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m stg[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mObject class = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTextGrid\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     47\u001b[0m         \u001b[39mand\u001b[39;00m (stg[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mFile type = \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mooTextFile short\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m stg[\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTextGrid\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m)):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../transcriptions_annotations/.ipynb_checkpoints/.ipynb_checkpoints.TextGrid'"
     ]
    }
   ],
   "source": [
    "transcription_dir = original_annotation\n",
    "\n",
    "tgsdict = dict()\n",
    "\n",
    "for experiment_name in sorted(os.listdir(transcription_dir)):\n",
    "    \n",
    "    if \".DS_Store\" in experiment_name:\n",
    "        continue\n",
    "        \n",
    "    tgsdict[experiment_name] = []\n",
    "    print(experiment_name) # r1, r2, r3...\n",
    "        \n",
    "    textgrid_file_name = transcription_dir + os.sep + experiment_name + os.sep + experiment_name + \".TextGrid\"\n",
    "    textgrid_file_name_target = target_dir + os.sep + experiment_name + os.sep + experiment_name + \".TextGrid\"\n",
    "    \n",
    "    # read textgrids\n",
    "    textgrid_dict = textgrid_to_dict(textgrid_file_name)\n",
    "    \n",
    "    for utts in textgrid_dict['A-utts']:\n",
    "        print(utts[2])\n",
    "        print(disfluency_tags(utts[2]))\n",
    "    \n",
    "    # tgt.io.write_to_file(textgrid, './disf_tags/'+str(f.split('/')[3].split('.')[0])+\".textgrid\")\n",
    "\n",
    "    # for uttsB in textgrid_dict['B-utts']:\n",
    "         \n",
    "    tgsdict[experiment_name].append(textgrid_dict)\n",
    "    # print(textgrid_file_name) # ./transcriptions_annotations/r1/r1.TextGrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e8710c6-9dea-4a25-859a-09523a18fb14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kann man ja einiges mit anfangen ne'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tg = tgsdict['r2']\n",
    "tg[0]['B-utts'][0][2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
